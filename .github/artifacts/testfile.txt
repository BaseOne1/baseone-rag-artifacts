However, the adoption rate isn’t the
true test of GenAI’s potential. Rather,
it’s the caliber of copy that it creates,
and its ability to personalize that
copy to individual customers. AI may
someday be capable of orchestrating
marketing campaigns as iconic as
Apple’s 1984 ad, but in ways
that resonate on an individual
level. For example, instead
of an iPhone ad highlighting
the device’s broad feature
suite, it could speak to the
specific interests of the
individual viewer.
The possibilities are endless,
but marketers must first work
out what’s to be considered
“fair play.” Right now, there’s
a decided split on how to
use AI in the content creation
process; two-thirds use GenAI
for creative brainstorming sessions,
first drafts, and outlines, while
49% say they rely on AI to produce
final content. Adoption is skewed
towards B2B companies, with 78%
using GenAI compared to 65% of
B2C companies
Image Creation
Chatbots
Audio/Voice
Application and Adoption Rates of Generative AI
Text Creation
50%
Coding
58%
36%
69%
37% AI is capable of generating several variations
of an image based on a description in seconds.
These images can then be used as ad creative,
concept images, or in other applications.
Chatbots have both business-facing and
consumer-facing applications, helping answer
questions, resolve issues, and streamline the
support process, as well as provide pCommon Roadblocks of
GenAI Adoption
11 BOTCO.AI | THE STATE OF GENAI CHATBOTS IN MARKETING
While GenAI has seen widespread
adoption and tangible benefits for
marketing agencies that use it, it’s not
without its faults. The most common
roadblock to adoption is the team
training required to use it effectively,
which 50% of respondents cited as
an issue. Meanwhile, 45% cited the
cost of generative AI and another 45%
cited privacy and security concerns
as obstacles.
Additionally, 24% of
respondents marked unethical biases as
a concern, a fear that isn’t unfounded
with generative AI content. AI is created
by humans, and is thus imperfect. If
it analyzes prejudiced or biased data,
it’s possible that it will recite that
information. It’s not uncommon for AI
tools to “hallucinate” — the longer some
AI engage in a single conversation, the
more likely it is that they’ll make up
facts or non-sequiturs.2 Marketers must
carefully choose their GenAI tools to
mitigate the risk of hallucinatory content
slipping through the cracks.
It certainly doesn’t help that there’s a
lack of parity in the content between AI
models. While some applications are
capable of stringing together complex
ideas in a way that seems relatively fluid
and natural3, that’s not necessarily true
across the board.
Even when these models write
confidently, they might not do it
competently. They typically train on
publicly available data, such as the
information one could find on Wikipedia.
As a result, AI will often cite erroneous
information in the text it generates.
Worse, inaccurate data is often
presented as truth.